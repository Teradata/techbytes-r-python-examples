{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################################################################\n",
    "# * The contents of this file are Teradata Public Content and have been released\n",
    "# * to the Public Domain.\n",
    "# * Tim Miller & Alexander Kolovos & Pankaj Vinod Purandare - Oct. 2019 - v.1.0\n",
    "# * Copyright (c) 2019 by Teradata\n",
    "# * Licensed under BSD; see \"license.txt\" file in the bundle root folder.\n",
    "#\n",
    "# ##############################################################################\n",
    "# R and Python TechBytes Demo - Part 3: teradataml\n",
    "# ------------------------------------------------------------------------------\n",
    "# File: R_Py_TechBytes-Part_3-Demo.ipynb\n",
    "# ------------------------------------------------------------------------------\n",
    "# The R and Python TechBytes Demo comprises of 5 parts:\n",
    "# Part 1 consists of only a Powerpoint overview of R and Python in Vantage\n",
    "# Part 2 demonstrates the Teradata R package tdplyr for clients\n",
    "# Part 3 demonstrates the Teradata Python package teradataml for clients\n",
    "# Part 4 demonstrates using R in-nodes with the SCRIPT and ExecR Table Operators\n",
    "# Part 5 demonstrates using Python in-nodes with the SCRIPT Table Operator\n",
    "# ##############################################################################\n",
    "#\n",
    "# This TechBytes demo utilizes a use case to predict the propensity of a\n",
    "# financial services customer base to open a credit card account.\n",
    "#\n",
    "# In Section 1, Various features will be generated by joining and aggregating\n",
    "# from 3 tables based tables (10K customers, 100K accounts, 1M+ transactions)\n",
    "# into an analytic data set. We will show how to use teradataml functions to do\n",
    "# the following:\n",
    "#\n",
    "#   a) Pull through the cust_id, income, age, years_with_bank, nbr_children\n",
    "#      from the Customer table\n",
    "#   b) Create a gender indicator variable (female_ind) from gender in the\n",
    "#      Customer table\n",
    "#   c) Create marital status indicator variables (single_ind, married_ind,\n",
    "#      seperated_ind) from marital_status in the Customer table\n",
    "#   d) Create location indicator variables (ca_resident, ny_resident,\n",
    "#      tx_resident, il_resident, az_resident, oh_resident) from state_code in\n",
    "#      Customer table\n",
    "#   e) Create account indicator variables (ck_acct_ind, cc_acct_ind,\n",
    "#      sv_acct_ind) from acct_type in the Account table\n",
    "#   f) Create average balance variables (ck_avg_bal, cc_avg_bal, sv_avg_bal)\n",
    "#      by taking the mean of the beginning_balance and ending_balance in the\n",
    "#      Account table\n",
    "#   g) Create average transaction amounts (ck_avg_tran_amt, cc_avg_tran_amt,\n",
    "#      sv_avg_tran_amt) by taking the average of the principal_amt and\n",
    "#      interest_amt in the Transactions table\n",
    "#   h) Create quarterly transaction counts (q1_nbr_trans, q2_nbr_trans,\n",
    "#      q3_nbr_trans, q4_nbr_trans) by taking the count of tran_id's based\n",
    "#      upon tran_date in the Transactions table\n",
    "#\n",
    "# In Section 2, we create an XGBoost model and a Decision Forest model on a\n",
    "# 60% sample of rows.\n",
    "# Furthermore, we test/score both models with the remaining 40%.\n",
    "# We conclude the present demo Part 3 with the following operations:\n",
    "# - Run decision forest evaluator to determine the most pertinent variables.\n",
    "# - Run confusion matrix on both scored data sets.\n",
    "# - Save the models so that they can be scored again in the future.\n",
    "#\n",
    "# Note: Code executed successfully on Python v.3.6.8, and by using teradataml\n",
    "#       v.16.20.00.03 to connect to a Vantage system that runs Advanced SQL\n",
    "#       Engine database v.16.20.34.01.\n",
    "# ##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load teradataml and dependency packages\n",
    "from teradataml import create_context, DataFrame, get_context, copy_to_sql, in_schema\n",
    "from teradataml import XGBoost, XGBoostPredict, DecisionForest, DecisionForestEvaluator, DecisionForestPredict, ConfusionMatrix\n",
    "from sqlalchemy.sql.expression import select, or_, extract, text, join, case as case_when\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a couple of functions that are used later in the demo code.\n",
    "def draw_box_plot(data, plotColumnName, xTicksColumnName, xLabel = None, yLabel = None, title = None):\n",
    "    \"\"\"\n",
    "    DESCRIPTION:\n",
    "        Function to display bar plot using the data based on the given parameters.\n",
    "\n",
    "    PARAMETERS:\n",
    "        data:\n",
    "            Required argument. A nx2 pandas dataframe with one column containing\n",
    "            numeric values.\n",
    "\n",
    "        plotColumnName:\n",
    "            Required argument. Column name of the pandas dataframe that contains\n",
    "            numeric values.\n",
    "\n",
    "        xTicksColumnName:\n",
    "            Required argument. Other column name for which count is given in\n",
    "            plotColumnName column values.\n",
    "\n",
    "        xLabel:\n",
    "            Optional argument. Name of the label on X-axis\n",
    "\n",
    "        yLabel:\n",
    "            Optional argument. Name of the label on Y-axis\n",
    "\n",
    "        title:\n",
    "            Optional argument. Title of the bar plot\n",
    "\n",
    "    RETURNS:\n",
    "        None\n",
    "    \"\"\"\n",
    "    index = np.arange(data.shape[0])\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.grid()\n",
    "    ax.bar(index, data[plotColumnName])\n",
    "    plt.xlabel(xLabel) if xLabel is not None else plt.xlabel(xTicksColumnName)\n",
    "    plt.ylabel(yLabel) if yLabel is not None else plt.ylabel(\"Count\")\n",
    "    plt.xticks(index, data[xTicksColumnName], rotation=30)\n",
    "    plt.title(title) if title is not None else plt.title(\"Bar Plot\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def processColumnToReplaceNullWithZero(column_expr, column_label):\n",
    "    \"\"\"\n",
    "    DESCRIPTION:\n",
    "        Function process SQLAlchemy column expression to replace NULL values with zeros,\n",
    "        else keep the value as is.\n",
    "\n",
    "    PARAMETERS:\n",
    "        column_expr:\n",
    "            Required Argument.\n",
    "            SQLAlchemy column expression.\n",
    "\n",
    "        column_label:\n",
    "            Required Argument.\n",
    "            New name of the processed column.\n",
    "\n",
    "    RETURNS:\n",
    "         SQLAlchemy Case object.\n",
    "    \"\"\"\n",
    "    return case_when([(column_expr == None, 0)], else_=column_expr).expression.label(column_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish connection to Teradata Vantage server (uses the Teradata SQL Driver\n",
    "# for Python). Before you execute the following statement, replace the variables\n",
    "# <HOSTNAME>, <UID> and <PWD> with your target Vantage system hostname (or\n",
    "# IP address), and your database user ID and password, respectively.\n",
    "td_context = create_context(host=\"<HOSTNAME>\", username=\"<UID>\", password=\"<PWD>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Data manipulation and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section, we start with our initial input tables and use teradataml\n",
    "# to perform a series of operations on the data. The goal is to produce an\n",
    "# Analytic Data Set (ADS) with the features we need for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for the Customer, Accounts and Transactions tables in the\n",
    "# Vantage Advanced SQL Engine. Before you execute the following statements, \n",
    "# replace the variable <DBNAME> with the target Vantage system database name\n",
    "# where the corresponding table resides.\n",
    "# Note: Use the in_schema() function only if tables reside in a database\n",
    "#       <DBNAME> other than the default database of the connected user.\n",
    "tdCustomer = DataFrame(in_schema(\"<DBNAME>\", \"Customer\"))\n",
    "# Using to_pandas() for a cleaner display format\n",
    "tdCustomer.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdAccounts = DataFrame(in_schema(\"<DBNAME>\", \"Accounts\"))\n",
    "# Using to_pandas() for a cleaner display format\n",
    "tdAccounts.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdTransactions = DataFrame(in_schema(\"<DBNAME>\", \"Transactions\"))\n",
    "# Using to_pandas() for a cleaner display format\n",
    "tdTransactions.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis: Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Histogram plot of income\n",
    "\n",
    "tdCustomer_hist_pd = tdCustomer[tdCustomer.income != None].to_pandas()\n",
    "# Note: to_pandas() converts the Teradata \"decimal.Decimal\" type into the Python\n",
    "#       non-numeric \"object\" type. For histogram, the column should be numeric\n",
    "#       type. Hence, we use astype() to convert the data type of column 'income'\n",
    "#       of pandas DataFrame.\n",
    "tdCustomer_hist_pd['income'] = tdCustomer_hist_pd['income'].astype('float64')\n",
    "tdCustomer_hist_pd.hist(column=\"income\", bins=30)\n",
    "plt.xlabel(\"income\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Histogram of column 'income'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bar plot: Number of customers gender-wise\n",
    "\n",
    "tdCustomer_bar_pd = tdCustomer.groupby(\"gender\").count().select(['gender','count_cust_id']).to_pandas()\n",
    "draw_box_plot(data = tdCustomer_bar_pd, plotColumnName = 'count_cust_id', xTicksColumnName = 'gender',\n",
    "              xLabel = \"Gender\", yLabel = \"No of customers\", title = \"Gender-wise customers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bar plot: Number of customers state-wise\n",
    "\n",
    "tdCustomer_bar_pd = tdCustomer.groupby(\"state_code\").count().select(['state_code','count_cust_id']).sort(['state_code']).to_pandas()\n",
    "draw_box_plot(data = tdCustomer_bar_pd, plotColumnName = 'count_cust_id', xTicksColumnName = 'state_code',\n",
    "              xLabel = \"State ID\", yLabel = \"No of customers\", title = \"State-wise customers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bar plot: Number of customers Marital status-wise\n",
    "\n",
    "tdCustomer_bar_pd = tdCustomer.groupby(\"marital_status\").count().select(['marital_status','count_cust_id']).sort(['marital_status']).to_pandas()\n",
    "draw_box_plot(data = tdCustomer_bar_pd, plotColumnName = 'count_cust_id', xTicksColumnName = 'marital_status',\n",
    "              xLabel = \"Marital Status\", yLabel = \"No of customers\", title = \"Marital status-wise customers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scatter plot: Starting and ending balance\n",
    "\n",
    "tdAccounts_pd = tdAccounts[tdAccounts.ending_balance != None].to_pandas()\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.grid()\n",
    "ax.scatter(tdAccounts_pd['starting_balance'], tdAccounts_pd['ending_balance'], s = 3)\n",
    "plt.xlabel(\"starting_balance\")\n",
    "plt.ylabel(\"ending_balance\")\n",
    "plt.title(\"Scatter plot of starting_balance and ending_balance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, grab the customer demographic variables and create indicator variables\n",
    "# for gender, marital_status and state_code (we consider a classification into\n",
    "# the top 6 states and the jointly the rest). To do so, initially we assemble\n",
    "# the list of columns to be projected in SQL. This list is constructed using\n",
    "# the SQLAlchemy objects 'Column' and 'Case'.\n",
    "# Note: The case_when() function is from SQLAlchemy. There exists a backlog\n",
    "#       story to implement this function in a future version of teradataml\n",
    "#       after October 2019.\n",
    "cust_select_query_column_projection = [tdCustomer.cust_id.expression,\n",
    "                                       tdCustomer.income.expression,\n",
    "                                       tdCustomer.age.expression,\n",
    "                                       tdCustomer.gender.expression,\n",
    "                                       tdCustomer.years_with_bank.expression,\n",
    "                                       tdCustomer.nbr_children.expression,\n",
    "                                       tdCustomer.marital_status.expression,\n",
    "                                       tdCustomer.state_code.expression,\n",
    "                                       case_when([(tdCustomer.gender.expression == \"F\", 1)], else_=0).expression.label(\"female\"),\n",
    "                                       case_when([(tdCustomer.marital_status.expression == \"1\", 1)], else_=0).expression.label(\"single\"),\n",
    "                                       case_when([(tdCustomer.marital_status.expression == \"2\", 1)], else_=0).expression.label(\"married\"),\n",
    "                                       case_when([(tdCustomer.marital_status.expression == \"3\", 1)], else_=0).expression.label(\"separated\"),\n",
    "                                       case_when([(tdCustomer.state_code.expression == \"CA\", 1)], else_=0).expression.label(\"ca_resident\"),\n",
    "                                       case_when([(tdCustomer.state_code.expression == \"NY\", 1)], else_=0).expression.label(\"ny_resident\"),\n",
    "                                       case_when([(tdCustomer.state_code.expression == \"TX\", 1)], else_=0).expression.label(\"tx_resident\"),\n",
    "                                       case_when([(tdCustomer.state_code.expression == \"IL\", 1)], else_=0).expression.label(\"il_resident\"),\n",
    "                                       case_when([(tdCustomer.state_code.expression == \"AZ\", 1)], else_=0).expression.label(\"az_resident\"),\n",
    "                                       case_when([(tdCustomer.state_code.expression == \"OH\", 1)], else_=0).expression.label(\"oh_resident\")\n",
    "                                       ]\n",
    "# The above is the column projection list that contains SQLAlchmey expressions.\n",
    "# The following statement constructs the SQL from the list, and uses it to create a DataFrame\n",
    "cust = DataFrame.from_query(str(select(cust_select_query_column_projection).compile(compile_kwargs={\"literal_binds\": True})))\n",
    "cust.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next: Get the account information required for the aggregation, and create\n",
    "# the indicator variables for acct_type\n",
    "acct_balance = tdAccounts.starting_balance + tdAccounts.ending_balance\n",
    "acct_select_query_column_projection = [tdAccounts.cust_id.expression,\n",
    "                                       tdAccounts.acct_type.expression,\n",
    "                                       tdAccounts.starting_balance.expression,\n",
    "                                       tdAccounts.ending_balance.expression,\n",
    "                                       tdAccounts.acct_nbr.expression,\n",
    "                                       case_when(\n",
    "                                           [\n",
    "                                               (\n",
    "                                                   tdAccounts.acct_type.expression == \"CK\", 1\n",
    "                                               )\n",
    "                                           ], else_=0).expression.label(\"ck_acct\"),\n",
    "                                       case_when(\n",
    "                                           [\n",
    "                                               (\n",
    "                                                   tdAccounts.acct_type.expression == \"SV\", 1\n",
    "                                               )\n",
    "                                           ], else_=0).expression.label(\"sv_acct\"),\n",
    "                                       case_when(\n",
    "                                           [\n",
    "                                               (\n",
    "                                                   tdAccounts.acct_type.expression == \"CC\", 1\n",
    "                                               )\n",
    "                                           ], else_=0).expression.label(\"cc_acct\"),\n",
    "                                       case_when(\n",
    "                                           [\n",
    "                                               (\n",
    "                                                   tdAccounts.acct_type.expression == \"CK\", acct_balance.expression\n",
    "                                               )\n",
    "                                           ], else_=0).expression.label(\"ck_bal\"),\n",
    "                                       case_when(\n",
    "                                           [\n",
    "                                               (\n",
    "                                                   tdAccounts.acct_type.expression == \"SV\", acct_balance.expression\n",
    "                                               )\n",
    "                                           ], else_=0).expression.label(\"sv_bal\"),\n",
    "                                       case_when(\n",
    "                                           [\n",
    "                                               (\n",
    "                                                   tdAccounts.acct_type.expression == \"CC\", acct_balance.expression\n",
    "                                               )\n",
    "                                           ], else_=0).expression.label(\"cc_bal\")\n",
    "                                       ]\n",
    "acct = DataFrame.from_query(str(select(acct_select_query_column_projection).compile(compile_kwargs={\"literal_binds\": True})))\n",
    "acct.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next: Get the transaction information required for the aggregation. Pull out\n",
    "# the quarter the transaction was made.\n",
    "trans_select_query_column_projection = [tdTransactions.acct_nbr.expression,\n",
    "                                        tdTransactions.principal_amt.expression,\n",
    "                                        tdTransactions.interest_amt.expression,\n",
    "                                        tdTransactions.tran_id.expression,\n",
    "                                        tdTransactions.tran_date.expression,\n",
    "                                        extract('month', tdTransactions.tran_date.expression).expression.label(\"acct_mon\"),\n",
    "                                        case_when(\n",
    "                                            [\n",
    "                                                (\n",
    "                                                    or_(\n",
    "                                                        text(\"acct_mon = '1'\"), text(\"acct_mon = '2'\"), text(\"acct_mon = '3'\"),\n",
    "                                                    ), 1\n",
    "                                                )\n",
    "                                            ], else_=0).expression.label(\"q1_trans\"),\n",
    "                                        case_when(\n",
    "                                            [\n",
    "                                                (\n",
    "                                                    or_(\n",
    "                                                        text(\"acct_mon = '4'\"), text(\"acct_mon = '5'\"), text(\"acct_mon = '6'\"),\n",
    "                                                    ), 1\n",
    "                                                )\n",
    "                                            ], else_=0).expression.label(\"q2_trans\"),\n",
    "                                        case_when(\n",
    "                                            [\n",
    "                                                (\n",
    "                                                    or_(\n",
    "                                                        text(\"acct_mon = '7'\"), text(\"acct_mon = '8'\"), text(\"acct_mon = '9'\"),\n",
    "                                                    ), 1\n",
    "                                                )\n",
    "                                            ], else_=0).expression.label(\"q3_trans\"),\n",
    "                                        case_when(\n",
    "                                            [\n",
    "                                                (\n",
    "                                                    or_(\n",
    "                                                        text(\"acct_mon = '10'\"), text(\"acct_mon = '11'\"), text(\"acct_mon = '12'\"),\n",
    "                                                    ), 1\n",
    "                                                )\n",
    "                                            ], else_=0).expression.label(\"q4_trans\")\n",
    "                                        ]\n",
    "\n",
    "trans = DataFrame.from_query(str(select(trans_select_query_column_projection).compile(compile_kwargs={\"literal_binds\": True})))\n",
    "trans.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Finally, pull everything together into an analytic data set\n",
    "\n",
    "# Initially, we wish to left join the acct and trans on 'acct_nbr' into \n",
    "# an acct_trans DataFrame.\n",
    "#\n",
    "# We construct the list of all column expressions to be projected. In this\n",
    "# process, we create new columns with the transaction amounts as follows:\n",
    "acct_trans_amt = trans.principal_amt + trans.interest_amt\n",
    "acct_trans_join_select_query_column_projection = [acct.cust_id.expression,\n",
    "                                                  acct.acct_type.expression,\n",
    "                                                  acct.starting_balance.expression,\n",
    "                                                  acct.ending_balance.expression,\n",
    "                                                  acct.acct_nbr.expression,\n",
    "                                                  trans.principal_amt.expression,\n",
    "                                                  trans.interest_amt.expression,\n",
    "                                                  trans.tran_id.expression,\n",
    "                                                  trans.tran_date.expression,\n",
    "                                                  trans.acct_mon.expression,\n",
    "                                                  trans.q1_trans.expression,\n",
    "                                                  trans.q2_trans.expression,\n",
    "                                                  trans.q3_trans.expression,\n",
    "                                                  trans.q4_trans.expression,\n",
    "                                                  acct.ck_acct.expression,\n",
    "                                                  acct.sv_acct.expression,\n",
    "                                                  acct.cc_acct.expression,\n",
    "                                                  acct.ck_bal.expression,\n",
    "                                                  acct.sv_bal.expression,\n",
    "                                                  acct.cc_bal.expression,\n",
    "                                                  case_when(\n",
    "                                                      [\n",
    "                                                          (\n",
    "                                                              acct.acct_type.expression == 'CK', acct_trans_amt.expression\n",
    "                                                          )\n",
    "                                                      ], else_=0).expression.label(\"ck_tran_amt\"),\n",
    "                                                  case_when(\n",
    "                                                      [\n",
    "                                                          (\n",
    "                                                              acct.acct_type.expression == 'SV', acct_trans_amt.expression\n",
    "                                                          )\n",
    "                                                      ], else_=0).expression.label(\"sv_tran_amt\"),\n",
    "                                                  case_when(\n",
    "                                                      [\n",
    "                                                          (\n",
    "                                                              acct.acct_type.expression == 'CC', acct_trans_amt.expression\n",
    "                                                          )\n",
    "                                                      ], else_=0).expression.label(\"cc_tran_amt\")\n",
    "                                                  ]\n",
    "\n",
    "# Construct SQL left outer join from clause statement by using the SQLAlchemy join() function.\n",
    "join_tbl_sqlalcmy = join(acct.acct_nbr.table, trans.acct_nbr.table, acct.acct_nbr.expression == trans.acct_nbr.expression, isouter=True)\n",
    "\n",
    "# Let us construct the SQL from the same and use it to create a DataFrame.\n",
    "acct_trans = DataFrame.from_query(str(select(acct_trans_join_select_query_column_projection).select_from(join_tbl_sqlalcmy).compile(compile_kwargs={\"literal_binds\": True})))\n",
    "acct_trans.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, perform a left outer join of acct_trans with cust on 'cust_id'.\n",
    "#\n",
    "# Now, we can use teradataml join API to join the two DataFrames, but we also\n",
    "# want to process few columns in a way that, if the column contains NULL, then\n",
    "# replace it with zero. To do so, we need a CASE object; for this reason, we\n",
    "# choose to use SQLAlchemy-style column selection and join operation. In the\n",
    "# following, we are using our DataFrame objects to pass ColumnExpression's\n",
    "# expression, which is SQLAlchmey Column object.\n",
    "ADS_Py_join_select_query_column_projection = [cust.cust_id.expression,\n",
    "                                              cust.income.expression,\n",
    "                                              cust.age.expression,\n",
    "                                              cust.gender.expression,\n",
    "                                              cust.years_with_bank.expression,\n",
    "                                              cust.nbr_children.expression,\n",
    "                                              cust.marital_status.expression,\n",
    "                                              cust.state_code.expression,\n",
    "                                              cust.female.expression,\n",
    "                                              cust.single.expression,\n",
    "                                              cust.married.expression,\n",
    "                                              cust.separated.expression,\n",
    "                                              cust.ca_resident.expression,\n",
    "                                              cust.ny_resident.expression,\n",
    "                                              cust.tx_resident.expression,\n",
    "                                              cust.il_resident.expression,\n",
    "                                              cust.az_resident.expression,\n",
    "                                              cust.oh_resident.expression,\n",
    "                                              acct_trans.acct_type.expression,\n",
    "                                              acct_trans.starting_balance.expression,\n",
    "                                              acct_trans.ending_balance.expression,\n",
    "                                              acct_trans.acct_nbr.expression,\n",
    "                                              acct_trans.principal_amt.expression,\n",
    "                                              acct_trans.interest_amt.expression,\n",
    "                                              acct_trans.tran_id.expression,\n",
    "                                              acct_trans.tran_date.expression,\n",
    "                                              acct_trans.acct_mon.expression,\n",
    "                                              processColumnToReplaceNullWithZero(acct_trans.q1_trans.expression, \"q1_trans\"),\n",
    "                                              processColumnToReplaceNullWithZero(acct_trans.q2_trans.expression, \"q2_trans\"),\n",
    "                                              processColumnToReplaceNullWithZero(acct_trans.q3_trans.expression, \"q3_trans\"),\n",
    "                                              processColumnToReplaceNullWithZero(acct_trans.q4_trans.expression, \"q4_trans\"),\n",
    "                                              processColumnToReplaceNullWithZero(acct_trans.ck_acct.expression, \"ck_acct\"),\n",
    "                                              processColumnToReplaceNullWithZero(acct_trans.sv_acct.expression, \"sv_acct\"),\n",
    "                                              processColumnToReplaceNullWithZero(acct_trans.cc_acct.expression, \"cc_acct\"),\n",
    "                                              processColumnToReplaceNullWithZero(acct_trans.ck_bal.expression, \"ck_bal\"),\n",
    "                                              processColumnToReplaceNullWithZero(acct_trans.sv_bal.expression, \"sv_bal\"),\n",
    "                                              processColumnToReplaceNullWithZero(acct_trans.cc_bal.expression, \"cc_bal\"),\n",
    "                                              processColumnToReplaceNullWithZero(acct_trans.ck_tran_amt.expression, \"ck_tran_amt\"),\n",
    "                                              processColumnToReplaceNullWithZero(acct_trans.sv_tran_amt.expression, \"sv_tran_amt\"),\n",
    "                                              processColumnToReplaceNullWithZero(acct_trans.cc_tran_amt.expression, \"cc_tran_amt\")\n",
    "                                             ]\n",
    "\n",
    "# Construct SQL left outer join from clause statement by using the SQLAlchemy join() function.\n",
    "join_cust_acct_trans_tbl_sqlalcmy = join(cust.cust_id.table, acct_trans.cust_id.table, cust.cust_id.expression == acct_trans.cust_id.expression, isouter=True)\n",
    "\n",
    "# Let us construct the SQL from the same and use it to create a DataFrame.\n",
    "ADS_Py_join = DataFrame.from_query(str(select(ADS_Py_join_select_query_column_projection).select_from(join_cust_acct_trans_tbl_sqlalcmy).compile(compile_kwargs={\"literal_binds\": True})))\n",
    "ADS_Py_join.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a last step, aggregate and roll up by 'cust_id' all variables in the above join operation.\n",
    "#\n",
    "# This pulls everything together into the analytic data set.\n",
    "ADS_Py = ADS_Py_join.groupby(\"cust_id\").agg(\n",
    "    {\n",
    "        \"income\" : \"min\",\n",
    "        \"age\" : \"min\",\n",
    "        \"years_with_bank\" : \"min\",\n",
    "        \"nbr_children\" : \"min\",\n",
    "        \"female\" : \"min\",\n",
    "        \"single\" : \"min\",\n",
    "        \"married\" : \"min\",\n",
    "        \"separated\" : \"min\",\n",
    "        \"ca_resident\" : \"max\",\n",
    "        \"ny_resident\" : \"max\",\n",
    "        \"tx_resident\" : \"max\",\n",
    "        \"il_resident\" : \"max\",\n",
    "        \"az_resident\" : \"max\",\n",
    "        \"oh_resident\" : \"max\",\n",
    "        \"ck_acct\" : \"max\",\n",
    "        \"sv_acct\" : \"max\",\n",
    "        \"cc_acct\" : \"max\",\n",
    "        \"ck_bal\" : \"mean\",\n",
    "        \"sv_bal\" : \"mean\",\n",
    "        \"cc_bal\" : \"mean\",\n",
    "        \"ck_tran_amt\" : \"mean\",\n",
    "        \"sv_tran_amt\" : \"mean\",\n",
    "        \"cc_tran_amt\" : \"mean\",\n",
    "        \"q1_trans\" : \"count\",\n",
    "        \"q2_trans\" : \"count\",\n",
    "        \"q3_trans\" : \"count\",\n",
    "        \"q4_trans\" : \"count\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Column names have been affected by aggregation. Assign final names.\n",
    "# Note: In teradataml, the rename() and column methods are unavailable yet.\n",
    "#       We use the assign() method combined with select() to achieve the task.\n",
    "columns = ['cust_id','tot_income','tot_age','tot_cust_years','tot_children','female_ind',\n",
    "           'single_ind', 'married_ind', 'separated_ind', 'ca_resident_ind', 'ny_resident_ind',\n",
    "           'tx_resident_ind','il_resident_ind','az_resident_ind', 'oh_resident_ind',\n",
    "           'ck_acct_ind','sv_acct_ind','cc_acct_ind', 'ck_avg_bal','sv_avg_bal','cc_avg_bal',\n",
    "           'ck_avg_tran_amt','sv_avg_tran_amt','cc_avg_tran_amt','q1_trans_cnt',\n",
    "           'q2_trans_cnt','q3_trans_cnt','q4_trans_cnt']\n",
    "\n",
    "ADS_Py = ADS_Py.assign(drop_columns = True,\n",
    "                       cust_id         = ADS_Py.cust_id,\n",
    "                       tot_income      = ADS_Py.min_income,\n",
    "                       tot_age         = ADS_Py.min_age,\n",
    "                       tot_cust_years  = ADS_Py.min_years_with_bank,\n",
    "                       tot_children    = ADS_Py.min_nbr_children,\n",
    "                       female_ind      = ADS_Py.min_female,\n",
    "                       single_ind      = ADS_Py.min_single,\n",
    "                       married_ind     = ADS_Py.min_married,\n",
    "                       separated_ind   = ADS_Py.min_separated,\n",
    "                       ca_resident_ind = ADS_Py.max_ca_resident,\n",
    "                       ny_resident_ind = ADS_Py.max_ny_resident,\n",
    "                       tx_resident_ind = ADS_Py.max_tx_resident,\n",
    "                       il_resident_ind = ADS_Py.max_il_resident,\n",
    "                       az_resident_ind = ADS_Py.max_az_resident,\n",
    "                       oh_resident_ind = ADS_Py.max_oh_resident,\n",
    "                       ck_acct_ind     = ADS_Py.max_ck_acct,\n",
    "                       sv_acct_ind     = ADS_Py.max_sv_acct,\n",
    "                       cc_acct_ind     = ADS_Py.max_cc_acct,\n",
    "                       ck_avg_bal      = ADS_Py.mean_ck_bal,\n",
    "                       sv_avg_bal      = ADS_Py.mean_sv_bal,\n",
    "                       cc_avg_bal      = ADS_Py.mean_cc_bal,\n",
    "                       ck_avg_tran_amt = ADS_Py.mean_ck_tran_amt,\n",
    "                       sv_avg_tran_amt = ADS_Py.mean_sv_tran_amt,\n",
    "                       cc_avg_tran_amt = ADS_Py.mean_cc_tran_amt,\n",
    "                       q1_trans_cnt    = ADS_Py.count_q1_trans,\n",
    "                       q2_trans_cnt    = ADS_Py.count_q2_trans,\n",
    "                       q3_trans_cnt    = ADS_Py.count_q3_trans,\n",
    "                       q4_trans_cnt    = ADS_Py.count_q4_trans).select(columns)\n",
    "\n",
    "# teradataml DataFrame creates views at the backend which are temporary. At the\n",
    "# end of the context removal, all temporary table/views perish. For this reason,\n",
    "# persist the output of ADS_Py as a table in the Advanced SQL Engine. First, DROP\n",
    "# the ADS_Py table, if it previously exists.\n",
    "try:\n",
    "    get_context().execute(\"DROP TABLE ADS_Py\")\n",
    "except:\n",
    "    pass\n",
    "copy_to_sql(ADS_Py, table_name=\"ADS_Py\", if_exists=\"replace\")\n",
    "\n",
    "# Create a DataFrame and take a glimpse at it.\n",
    "tdADS_Py = DataFrame(\"ADS_Py\")\n",
    "tdADS_Py.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Alternatively, optimized written SQL can be used to create the analytic\n",
    "#       data set, as shown in the following:\n",
    "# Before you execute the following statement, replace the variable <DBNAME> with\n",
    "# the target Vantage system database name where the corresponding table resides.\n",
    "ADS_SQL =\"SELECT \\\n",
    "T1.cust_id  AS cust_id \\\n",
    ",MIN(T1.income) AS tot_income \\\n",
    ",MIN(T1.age) AS tot_age \\\n",
    ",MIN(T1.years_with_bank) AS tot_cust_years \\\n",
    ",MIN(T1.nbr_children) AS tot_children \\\n",
    ",CASE WHEN MIN(T1.marital_status) = 1 THEN 1 ELSE 0 END AS single_ind \\\n",
    ",CASE WHEN MIN(T1.gender) = 'F' THEN 1 ELSE 0 END AS female_ind \\\n",
    ",CASE WHEN MIN(T1.marital_status) = 2 THEN 1 ELSE 0 END AS married_ind \\\n",
    ",CASE WHEN MIN(T1.marital_status) = 3 THEN 1 ELSE 0 END AS separated_ind \\\n",
    ",MAX(CASE WHEN T1.state_code = 'CA' THEN 1 ELSE 0 END) AS ca_resident_ind \\\n",
    ",MAX(CASE WHEN T1.state_code = 'NY' THEN 1 ELSE 0 END) AS ny_resident_ind \\\n",
    ",MAX(CASE WHEN T1.state_code = 'TX' THEN 1 ELSE 0 END) AS tx_resident_ind \\\n",
    ",MAX(CASE WHEN T1.state_code = 'IL' THEN 1 ELSE 0 END) AS il_resident_ind \\\n",
    ",MAX(CASE WHEN T1.state_code = 'AZ' THEN 1 ELSE 0 END) AS az_resident_ind \\\n",
    ",MAX(CASE WHEN T1.state_code = 'OH' THEN 1 ELSE 0 END) AS oh_resident_ind \\\n",
    ",MAX(CASE WHEN T2.acct_type = 'CK' THEN 1 ELSE 0 END) AS ck_acct_ind \\\n",
    ",MAX(CASE WHEN T2.acct_type = 'SV' THEN 1 ELSE 0 END) AS sv_acct_ind \\\n",
    ",MAX(CASE WHEN T2.acct_type = 'CC' THEN 1 ELSE 0 END) AS cc_acct_ind \\\n",
    ",AVG(CASE WHEN T2.acct_type = 'CK' THEN T2.starting_balance+T2.ending_balance ELSE 0 END) AS ck_avg_bal \\\n",
    ",AVG(CASE WHEN T2.acct_type = 'SV' THEN T2.starting_balance+T2.ending_balance ELSE 0 END) AS sv_avg_bal \\\n",
    ",AVG(CASE WHEN T2.acct_type = 'CC' THEN T2.starting_balance+T2.ending_balance ELSE 0 END) AS cc_avg_bal \\\n",
    ",AVG(CASE WHEN T2.acct_type = 'CK' THEN T3.principal_amt+T3.interest_amt ELSE 0 END) AS ck_avg_tran_amt \\\n",
    ",AVG(CASE WHEN T2.acct_type = 'SV' THEN T3.principal_amt+T3.interest_amt ELSE 0 END) AS sv_avg_tran_amt \\\n",
    ",AVG(CASE WHEN T2.acct_type = 'CC' THEN T3.principal_amt+T3.interest_amt ELSE 0 END) AS cc_avg_tran_amt \\\n",
    ",COUNT(CASE WHEN ((EXTRACT(MONTH FROM T3.tran_date) + 2) / 3) = 1 THEN T3.tran_id ELSE NULL END) AS q1_trans_cnt \\\n",
    ",COUNT(CASE WHEN ((EXTRACT(MONTH FROM T3.tran_date) + 2) / 3) = 2 THEN T3.tran_id ELSE NULL END) AS q2_trans_cnt \\\n",
    ",COUNT(CASE WHEN ((EXTRACT(MONTH FROM T3.tran_date) + 2) / 3) = 3 THEN T3.tran_id ELSE NULL END) AS q3_trans_cnt \\\n",
    ",COUNT(CASE WHEN ((EXTRACT(MONTH FROM T3.tran_date) + 2) / 3) = 4 THEN T3.tran_id ELSE NULL END) AS q4_trans_cnt \\\n",
    "FROM <DBNAME>.Customer AS T1 \\\n",
    "LEFT OUTER JOIN <DBNAME>.Accounts AS T2 \\\n",
    "ON T1.cust_id = T2.cust_id \\\n",
    "LEFT OUTER JOIN <DBNAME>.Transactions AS T3 \\\n",
    "ON T2.acct_nbr = T3.acct_nbr \\\n",
    "GROUP BY T1.cust_id\"\n",
    "\n",
    "# As earlier, DROP the ADS_Py table, if it previously exists.\n",
    "# In this case, create a DataFrame with from_query() and take a glimpse at it.\n",
    "try:\n",
    "    get_context().execute(\"DROP TABLE ADS_SQL\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "tdADS_SQL = DataFrame.from_query(ADS_SQL)\n",
    "tdADS_SQL.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Model fitting with the Vantage Analytic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section, we use the ADS that we created in Section 1 above to perform\n",
    "# model fitting and scoring tasks. We illustrate using teradataml functions that\n",
    "# invoke the XGBoost and Decision Forest algorithms from corresponding analytic\n",
    "# functions that reside in the Vantage Machine Learning Engine of the connected \n",
    "# Vantage system.\n",
    "# Note: To continue into Section 2 of this demo, you must have access\n",
    "#       to a Vantage system with a Machine Learning Engine component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and testing DataSets from the persisted table 'ADS_Py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the analytic data set into training and testing data sets (60/40%)\n",
    "# Note: A future version of teradataml will feature a Sample API for sampling\n",
    "#       tasks so that SQL can be avoided.\n",
    "ADS_Train_Test = \"SELECT cust_id\\\n",
    "                         ,tot_income\\\n",
    "                         ,tot_age\\\n",
    "                         ,tot_cust_years\\\n",
    "                         ,tot_children\\\n",
    "                         ,female_ind\\\n",
    "                         ,single_ind\\\n",
    "                         ,married_ind\\\n",
    "                         ,separated_ind\\\n",
    "                         ,ca_resident_ind\\\n",
    "                         ,ny_resident_ind\\\n",
    "                         ,tx_resident_ind\\\n",
    "                         ,il_resident_ind\\\n",
    "                         ,az_resident_ind\\\n",
    "                         ,oh_resident_ind\\\n",
    "                         ,ck_acct_ind\\\n",
    "                         ,sv_acct_ind\\\n",
    "                         ,cc_acct_ind\\\n",
    "                         ,ck_avg_bal\\\n",
    "                         ,sv_avg_bal\\\n",
    "                         ,cc_avg_bal\\\n",
    "                         ,ck_avg_tran_amt\\\n",
    "                         ,sv_avg_tran_amt\\\n",
    "                         ,cc_avg_tran_amt\\\n",
    "                         ,q1_trans_cnt\\\n",
    "                         ,q2_trans_cnt\\\n",
    "                         ,q3_trans_cnt\\\n",
    "                         ,q4_trans_cnt\\\n",
    "                         ,SAMPLEID AS sample_id\\\n",
    "                 FROM ADS_Py SAMPLE .60, .40\"\n",
    "\n",
    "# Create a DataFrame from_query() and take a glimpse at it\n",
    "tdTrain_Test = DataFrame.from_query(ADS_Train_Test)\n",
    "tdTrain_Test.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the 60% sample to train.\n",
    "TrainQuery = tdTrain_Test[tdTrain_Test.sample_id == \"1\"]\n",
    "\n",
    "# Use the 40% sample to test/score.\n",
    "TestQuery = tdTrain_Test[tdTrain_Test.sample_id == \"2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and scoring using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, construct a formula to predict Credit Card account ownership based on independent variables of interest:\n",
    "formula = \"cc_acct_ind ~ tot_income + tot_age + tot_cust_years + tot_children + female_ind + single_ind \" \\\n",
    "          \"+ married_ind + separated_ind + ca_resident_ind + ny_resident_ind + tx_resident_ind + il_resident_ind \" \\\n",
    "          \"+ az_resident_ind + oh_resident_ind + ck_acct_ind + sv_acct_ind + ck_avg_bal + sv_avg_bal \" \\\n",
    "          \"+ ck_avg_tran_amt + sv_avg_tran_amt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, train an XGBoost model to predict Credit Card account ownership on the basis of the above formula.\n",
    "td_xgboost_model = XGBoost(data=TrainQuery,\n",
    "                           id_column='cust_id',\n",
    "                           formula = formula,\n",
    "                           num_boosted_trees=4,\n",
    "                           loss_function='binomial',\n",
    "                           prediction_type='classification',\n",
    "                           reg_lambda=1.0,\n",
    "                           shrinkage_factor=0.1,\n",
    "                           iter_num=10,\n",
    "                           min_node_size=1,\n",
    "                           max_depth=10\n",
    "                           )\n",
    "print(td_xgboost_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the XGBoost model against the holdout and compare actuals to predicted.\n",
    "td_xgboost_predict = XGBoostPredict(td_xgboost_model,\n",
    "                                    newdata=TestQuery,\n",
    "                                    object_order_column= ['tree_id','iter','class_num'],\n",
    "                                    id_column='cust_id',\n",
    "                                    terms='cc_acct_ind',\n",
    "                                    num_boosted_trees=4\n",
    "                                    )\n",
    "\n",
    "# Persist the XGBoostPredict output.\n",
    "try:\n",
    "    get_context().execute(\"DROP TABLE XGBoost_Scores\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "td_xgboost_predict.result.to_sql(if_exists = \"replace\", table_name = \"XGBoost_Scores\")\n",
    "tdXGBoost_Scores = DataFrame(\"XGBoost_Scores\")\n",
    "tdXGBoost_Scores.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and scoring using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a different approach, train a Random Forest model to predict the same target,\n",
    "# so we can compare and see which algorithm fits best the data.\n",
    "td_decisionforest_model = DecisionForest(formula = formula,\n",
    "                                         data = TrainQuery,\n",
    "                                         tree_type = \"classification\",\n",
    "                                         ntree = 500,\n",
    "                                         nodesize = 1,\n",
    "                                         variance = 0.0,\n",
    "                                         max_depth = 12,\n",
    "                                         mtry = 5,\n",
    "                                         mtry_seed = 100,\n",
    "                                         seed = 100\n",
    "                                         )\n",
    "print(td_decisionforest_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the DecisionForestEvaluator() function to determine the most important\n",
    "# variables in the Decision Forest model.\n",
    "td_decisionforest_model_evaluator = DecisionForestEvaluator(object = td_decisionforest_model,\n",
    "                                                            num_levels = 5)\n",
    "# In the following, the describe() method provides summary statistics across\n",
    "# the trees over grouping by each variable. One can consider the mean\n",
    "# importance across all trees as the importance for each variable.\n",
    "td_variable_importance = td_decisionforest_model_evaluator.result.select([\"variable_col\", \"importance\"]).groupby(\"variable_col\").describe()\n",
    "print(td_variable_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the Decision Forest model.\n",
    "td_decisionforest_predict = DecisionForestPredict(td_decisionforest_model,\n",
    "                                                  newdata = TestQuery,\n",
    "                                                  id_column = \"cust_id\",\n",
    "                                                  detailed = False,\n",
    "                                                  terms = [\"cc_acct_ind\"]\n",
    "                                                  )\n",
    "\n",
    "# Persist the DecisionForestPredict output.\n",
    "try:\n",
    "    get_context().execute(\"DROP TABLE RandomForest_Scores\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "copy_to_sql(td_decisionforest_predict.result, if_exists = \"replace\", table_name=\"RandomForest_Scores\")\n",
    "tdRandomForest_Scores = DataFrame(\"RandomForest_Scores\")\n",
    "tdRandomForest_Scores.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Confusion Matrix to look at the 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the confusion matrix for the XGBoost model.\n",
    "confusion_matrix_XGB = ConfusionMatrix(data = tdXGBoost_Scores,\n",
    "                                       reference = \"cc_acct_ind\",\n",
    "                                       prediction = \"prediction\"\n",
    "                                       )\n",
    "print(confusion_matrix_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the confusion matrix for Random Forest model.\n",
    "confusion_matrix_DF = ConfusionMatrix(data = tdRandomForest_Scores,\n",
    "                                      reference = \"cc_acct_ind\",\n",
    "                                      prediction = \"prediction\"\n",
    "                                      )\n",
    "print(confusion_matrix_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving models to be reused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Model Administration APIs are not officially supported in teradataml v.16.20.00.03\n",
    "#       and their APIs are not exposed to end user.\n",
    "from teradataml import save_model, list_models, describe_model, delete_model, retrieve_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the models so that they can be scored again and managed moving forward.\n",
    "# Expect an error if you ask to save a model with an existing specified name.\n",
    "save_model(td_xgboost_model, name=\"XGBoost_Model_1\")\n",
    "save_model(td_decisionforest_model, name=\"Decision_Forest_Model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show some other methods for model maintenance\n",
    "\n",
    "# List existing saved models.\n",
    "list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide description of a specified model.\n",
    "# Expect an error if a specified model does not exist.\n",
    "describe_model(name = \"Decision_Forest_Model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve saved models and use these in a different session to score.\n",
    "# Expect an error if a specified model does not exist.\n",
    "xgboost_model = retrieve_model(name = \"XGBoost_Model_1\")\n",
    "decision_forest_model = retrieve_model(name=\"Decision_Forest_Model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a saved model.\n",
    "# Expect an error if a specified model does not exist.\n",
    "delete_model(name=\"XGBoost_Model_1\")\n",
    "delete_model(name=\"Decision_Forest_Model_1\")\n",
    "list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the context of present teradataml session and terminate the Python session.\n",
    "# It is recommended to call the remove_context() function for session cleanup.\n",
    "# Temporary objects are removed at the end of the session.\n",
    "from teradataml import remove_context\n",
    "remove_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
